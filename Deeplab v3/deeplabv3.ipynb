{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deeplab v3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from keras.layers import *\n",
    "\n",
    "import nibabel as nib\n",
    "from nilearn import plotting\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "import mia_datasets_tf as mia_data\n",
    "import mia_evaluation as mia_eval\n",
    "import mia_losses_tf as mia_losses\n",
    "import mia_utils\n",
    "import SimpleITK as sitk\n",
    "import os \n",
    "import shutil\n",
    "import inspect\n",
    "import random\n",
    "\n",
    "sitk.ProcessObject_SetGlobalWarningDisplay(False)\n",
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_directory = r\"/ssd2/jupyter/MIA/deeplabv3\"\n",
    "\n",
    "if not os.path.exists(model_directory):\n",
    "    os.makedirs(model_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(model_creator, fit_params, num_runs, directory, name):\n",
    "    best_val_loss = float('inf')\n",
    "    best_model_path = None\n",
    "\n",
    "    val_losses = []\n",
    "\n",
    "    valid_fit_args = inspect.signature(tf.keras.Model.fit).parameters.keys()\n",
    "    filtered_fit_params = {key: value for key, value in fit_params.items() if key in valid_fit_args}\n",
    "\n",
    "    for run in range(num_runs):\n",
    "        print(f\"Training run {run + 1}/{num_runs}\\n\")\n",
    "        model = model_creator()\n",
    "\n",
    "        run_model_path = os.path.join(directory, f\"{name}_{run}.keras\")\n",
    "\n",
    "        checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(filepath=run_model_path, monitor='val_loss', save_best_only=True, mode='min')\n",
    "\n",
    "        if \"callbacks\" in filtered_fit_params:\n",
    "            filtered_fit_params['callbacks'].append(checkpoint_cb)\n",
    "        else:\n",
    "            filtered_fit_params['callbacks'] = [checkpoint_cb]\n",
    "    \n",
    "        history = model.fit(\n",
    "            fit_params['training_data'],\n",
    "            **filtered_fit_params)\n",
    "\n",
    "        val_loss = min(history.history['val_loss'])\n",
    "        val_losses.append(history.history['val_loss'])\n",
    "\n",
    "        print(f\"\\nRun {run + 1} best val_loss = {val_loss:.6f}\")\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            print(f\"New best model found\")\n",
    "            best_val_loss = val_loss\n",
    "            best_model_path = run_model_path\n",
    "\n",
    "    print(f\"\\n Best model: {best_model_path} with val_loss = {best_val_loss:.6f}\")\n",
    "\n",
    "    return best_model_path, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_side_by_side(images : list[np.ndarray], titles : list[str] | None):\n",
    "    fig, axs = plt.subplots(1, len(images), figsize=(15, 5))\n",
    "    \n",
    "    for index, image in enumerate(images):\n",
    "        axs[index].imshow(image[image.shape[0] // 2])\n",
    "        if titles is not None:\n",
    "            axs[index].set_title(titles[index])\n",
    "        axs[index].axis('off')\n",
    "\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_history(history, y_lim=(0.0, 1.5)):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for i, run_val_loss in enumerate(history):\n",
    "        plt.plot(run_val_loss, label=f'Run {i + 1}')\n",
    "\n",
    "    plt.title('Validation Loss Across Runs')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Validation Loss')\n",
    "    plt.ylim(y_lim)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_all(seed=2141):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [(255, 60, 60), (140, 255, 140), (140, 200, 255)] \n",
    "custom_cmap = ListedColormap(colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slicer = mia_data.create_slicer(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_slices(dataset, row_size):\n",
    "    num_slices = len(dataset)\n",
    "    num_cols = min(8, num_slices)\n",
    "    num_rows = (num_slices + num_cols - 1) // num_cols\n",
    "\n",
    "    plt.figure(figsize=(8, num_rows * row_size))\n",
    "    for i, slice_data in enumerate(dataset):\n",
    "        plt.subplot(num_rows, num_cols, i + 1)\n",
    "        plt.imshow(slice_data[0].numpy(), cmap='gray')  \n",
    "        plt.axis('off') \n",
    "        plt.title(f\"Slice {i + 1}\") \n",
    "   \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(input_layer, num_filters, kernel_size=3, strides=1, dilation_rate=1,\n",
    "                use_bias=False, padding='same', activation='relu', name=\"\"):\n",
    "        layer = Conv2D(filters=num_filters, kernel_size=kernel_size, strides=strides, \n",
    "                       dilation_rate=dilation_rate, use_bias=use_bias, padding=padding,\n",
    "                         kernel_initializer=\"he_normal\", name=f\"{name}_conv\")(input_layer)\n",
    "        layer = BatchNormalization(name=f\"{name}_norm\")(layer)\n",
    "        if activation:\n",
    "            layer = Activation(activation, name=f\"{name}_acti\")(layer)\n",
    "        return layer\n",
    "\n",
    "def encoder_block(input_layer, filters, name=\"\", pooling=True):\n",
    "    layer = input_layer\n",
    "    for i, f in enumerate(filters):\n",
    "        layer = conv_block(layer, num_filters=f, name=f'{name}_block{i}')\n",
    "    if pooling:\n",
    "        layer = MaxPooling2D((2, 2), name=f'{name}_maxpool')(layer)\n",
    "    return layer\n",
    "\n",
    "def aspp_block(input_layer, num_filters, name=\"\"):\n",
    "    dims = input_layer.shape\n",
    "\n",
    "    out_pool = AveragePooling2D(pool_size=dims[-3:-1], name=f\"{name}_avrg_pool\")(input_layer)\n",
    "    out_pool = conv_block(out_pool, num_filters=num_filters, kernel_size=1, use_bias=True, name=f\"{name}_conv1\")\n",
    "    out_pool = UpSampling2D(size=dims[-3:-1], interpolation=\"bilinear\", name=f\"{name}_upsampl\")(out_pool)\n",
    "\n",
    "    out_1 = conv_block(input_layer, num_filters=num_filters, kernel_size=1, dilation_rate=1, name=f\"{name}_conv2\")\n",
    "    out_4 = conv_block(input_layer, num_filters=num_filters, kernel_size=3, dilation_rate=4, name=f\"{name}_conv3\")\n",
    "    out_8 = conv_block(input_layer, num_filters=num_filters, kernel_size=3, dilation_rate=8, name=f\"{name}_conv4\")\n",
    "\n",
    "    layer = Concatenate(axis=-1, name=f\"{name}_concat\")([out_pool, out_1, out_4, out_8])\n",
    "    output_layer = conv_block(layer, num_filters=num_filters, kernel_size=1, name=f\"{name}_conv5\")\n",
    "\n",
    "    return output_layer    \n",
    "\n",
    "def deeplabv3_compiled(input_size, n_classes=1, learning_rate=0.0001, enc_filters=32, aspp_filters=256):\n",
    "    inputs = Input(input_size[-3:], name='inputs')\n",
    "\n",
    "    encoder_1 = encoder_block(inputs, filters=(enc_filters, enc_filters), name=\"enc_1\")\n",
    "    encoder_2 = encoder_block(encoder_1, filters=(enc_filters * 2, enc_filters * 2), name=\"enc_2\")\n",
    "    encoder_3 = encoder_block(encoder_2, filters=(enc_filters * 4, enc_filters * 4), name=\"enc_3\")\n",
    "\n",
    "    aspp = aspp_block(encoder_3, num_filters=aspp_filters, name=\"aspp\")\n",
    "    dec_input_a = UpSampling2D(size=(input_size[0] // aspp.shape[-3] // 2, input_size[1] // aspp.shape[-2] // 2),\n",
    "                                interpolation=\"bilinear\", name=\"dec_input_a\")(aspp)\n",
    "\n",
    "    dec_input_b = conv_block(encoder_1, num_filters=64, kernel_size=1, name=\"dec_input_b\")\n",
    "\n",
    "    layer = Concatenate(axis=-1, name=\"dec_concat\")([dec_input_a, dec_input_b])\n",
    "    layer = conv_block(layer, num_filters=128, kernel_size=3, name=f\"dec_conv\")\n",
    "    layer = UpSampling2D(size=(input_size[0] // layer.shape[-3], input_size[1] // layer.shape[-2]),\n",
    "                          interpolation=\"bilinear\", name=\"dec_output\")(layer)\n",
    "\n",
    "    outputs = conv_block(layer, num_filters=n_classes, kernel_size=1, activation='Softmax', name=\"outputs\")\n",
    "\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs, name=\"DeepLabV3\")\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "                   loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "              metrics=[keras.metrics.SparseCategoricalAccuracy(name=\"sparse_categorical_accuracy\")])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iseg 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iseg2019_training = mia_data.Iseg2019Processed(r'/ssd2/jupyter/MIA/split_datasets/iseg2019_ns/training')\n",
    "iseg2019_validation = mia_data.Iseg2019Processed(r'/ssd2/jupyter/MIA/split_datasets/iseg2019_ns/validation')\n",
    "iseg2019_testing = mia_data.Iseg2019Processed(r'/ssd2/jupyter/MIA/split_datasets/iseg2019_ns/testing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_specific_directory = os.path.join(model_directory, \"iseg2019_ns\")\n",
    "if not os.path.exists(dataset_specific_directory):\n",
    "    os.makedirs(dataset_specific_directory)\n",
    "\n",
    "inference_directory = os.path.join(dataset_specific_directory, \"inference\")\n",
    "if not os.path.exists(inference_directory):\n",
    "    os.makedirs(inference_directory)\n",
    "\n",
    "labels_dictionary = {\"CSF\" : 1, \"GM\" : 2, \"WM\" : 3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = iseg2019_training.subjects[0].get_T1()\n",
    "t2 = iseg2019_training.subjects[0].get_T2()\n",
    "label = iseg2019_training.subjects[0].get_label()\n",
    "\n",
    "plot_side_by_side([sitk.GetArrayViewFromImage(t1), sitk.GetArrayViewFromImage(t2), sitk.GetArrayViewFromImage(label)], [\"T1\", \"T2\", \"Label\"] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing = mia_data.Iseg2019Processed('/ssd2/jupyter/MIA/split_datasets/iseg2019_ns/testing').T2_dataset()\n",
    "\n",
    "input_shape = next(testing.take(1).as_numpy_iterator())[0].shape\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sliced_example = testing.take(1).flat_map(mia_data.create_slicer(0))\n",
    "plot_slices([x for x in sliced_example], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sliced_example = testing.take(1).flat_map(mia_data.create_slicer(1))\n",
    "plot_slices([x for x in sliced_example], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sliced_example = testing.take(1).flat_map(mia_data.create_slicer(2))\n",
    "plot_slices([x for x in sliced_example], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T1 + T2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = os.path.join(dataset_specific_directory, \"iseg2019_T1T2.keras\")\n",
    "\n",
    "training_cropped = iseg2019_training.T1_T2_dataset()\n",
    "validation_cropped = iseg2019_validation.T1_T2_dataset()\n",
    "testing = iseg2019_testing.T1_T2_dataset()\n",
    "\n",
    "batch_size = 128\n",
    "num_channels = 2\n",
    "training_cropped = training_cropped.flat_map(slicer).shuffle(512).batch(batch_size)\n",
    "validation_cropped = validation_cropped.flat_map(slicer).shuffle(512).batch(batch_size)\n",
    "\n",
    "slices = next(training_cropped.take(1).as_numpy_iterator())\n",
    "\n",
    "input_shape = (slices[0].shape[1:])\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplab_creator = lambda : deeplabv3_compiled(input_size=input_shape, n_classes=len(labels_dictionary) + 1, learning_rate=0.0001)\n",
    "\n",
    "callbacks_list = [\n",
    "    keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=50),\n",
    "]\n",
    "\n",
    "fit_params = {\n",
    "    \"callbacks\" : callbacks_list,\n",
    "    \"training_data\" : training_cropped,\n",
    "    \"validation_data\" : validation_cropped,\n",
    "    'epochs' : 1000\n",
    "}\n",
    "\n",
    "seed_all()\n",
    "best_model_path, history = run_training(deeplab_creator, fit_params, 5, dataset_specific_directory, \"iseg2019_T1T2\")\n",
    "\n",
    "if os.path.exists(model_file):\n",
    "    os.remove(model_file)\n",
    "    \n",
    "shutil.copy(best_model_path, model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplab = keras.saving.load_model(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_slices  = testing.flat_map(slicer).batch(1)\n",
    "\n",
    "prediction = deeplab.predict(testing_slices)\n",
    "predicted_labels = prediction.argmax(axis=-1)\n",
    "\n",
    "mia_utils.writeImagesArray(predicted_labels, inference_directory, lambda x : f\"T1_T2{x}.nii.gz\", lambda x : iseg2019_testing.subjects[x].get_label())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mia_utils.interactive_display(predicted_labels, (1,3), \"Iseg 2019 T1 + T2 Inference\", cmap=custom_cmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mia_utils.interactive_display(next(testing.take(1).as_numpy_iterator())[1], (1,3), title=\"Iseg 2019 T1+T2 Ground truth\", cmap=custom_cmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_image = sitk.GetImageFromArray(predicted_labels)\n",
    "truth_image = sitk.GetImageFromArray(testing.as_numpy_iterator().next()[1])\n",
    "\n",
    "eval = mia_eval.evaluateImage(predicted_image, truth_image, labels_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mia_eval.createRecord(\"iseg2019\", eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.experimental.get_memory_info('GPU:0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BONBID-HIE 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bondid2023_training = mia_data.BONDID2023Processed(r'/ssd2/jupyter/MIA/split_datasets/bonbid2023_ns/training', \"nii.gz\")\n",
    "bondid2023_validation = mia_data.BONDID2023Processed(r'/ssd2/jupyter/MIA/split_datasets/bonbid2023_ns/validation',  \"nii.gz\")\n",
    "bondid2023_testing = mia_data.BONDID2023Processed(r'/ssd2/jupyter/MIA/split_datasets/bonbid2023_ns/testing',  \"nii.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_specific_directory = os.path.join(model_directory, \"bonbid2023_ns\")\n",
    "if not os.path.exists(dataset_specific_directory):\n",
    "    os.makedirs(dataset_specific_directory)\n",
    "\n",
    "inference_directory = os.path.join(dataset_specific_directory, \"inference\")\n",
    "if not os.path.exists(inference_directory):\n",
    "    os.makedirs(inference_directory)\n",
    "\n",
    "labels_dictionary = {\"Lesion\" : 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adc = bondid2023_training.subjects[0].get_ADC_ss()\n",
    "z_adc = bondid2023_training.subjects[0].get_Z_ADC()\n",
    "label = bondid2023_training.subjects[0].get_label()\n",
    "\n",
    "plot_side_by_side([sitk.GetArrayViewFromImage(adc), sitk.GetArrayViewFromImage(z_adc), sitk.GetArrayViewFromImage(label)], [\"ADC_ss\", \"Z_ADC\", \"Label\"] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sliced_example = bondid2023_testing.ADC_ss_dataset().take(1).flat_map(mia_data.create_slicer(0))\n",
    "plot_slices([x for x in sliced_example], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ADC + Z_ADC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = os.path.join(dataset_specific_directory, \"bonbid2023_adc_zadc.keras\")\n",
    "\n",
    "training = bondid2023_training.ADC_ss_Z_ADC_dataset()\n",
    "testing = bondid2023_testing.ADC_ss_Z_ADC_dataset()\n",
    "validation = bondid2023_validation.ADC_ss_Z_ADC_dataset()\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "training = training.flat_map(slicer).batch(batch_size)\n",
    "validation = validation.flat_map(slicer).batch(batch_size)\n",
    "\n",
    "slices = next(training.take(1).as_numpy_iterator())\n",
    "\n",
    "input_shape = slices[0].shape[1:]\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplab_creator = lambda : deeplabv3_compiled(input_size=input_shape, n_classes=len(labels_dictionary) + 1, learning_rate=0.0001)\n",
    "\n",
    "callbacks_list = [\n",
    "    keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=50),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau( monitor='val_loss', factor=0.5, patience=10, min_lr=1e-6)\n",
    "]\n",
    "\n",
    "fit_params = {\n",
    "    \"callbacks\" : callbacks_list,\n",
    "    \"training_data\" : training,\n",
    "    \"validation_data\" : validation,\n",
    "    'epochs' : 1000\n",
    "}\n",
    "\n",
    "seed_all()\n",
    "best_model_path, history = run_training(deeplab_creator, fit_params, 5, dataset_specific_directory, \"bonbid2023_adc_zadc\")\n",
    "\n",
    "if os.path.exists(model_file):\n",
    "    shutil.rmtree(model_file)\n",
    "    \n",
    "shutil.copy(best_model_path, model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplab = keras.saving.load_model(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluations = []\n",
    "\n",
    "for index, img in enumerate(testing):\n",
    "    prediction = deeplab.predict(img[0])\n",
    "    predicted_labels = tf.math.argmax(prediction, -1).numpy()\n",
    "\n",
    "    metrics = mia_eval.evaluateImage(sitk.GetImageFromArray(predicted_labels), sitk.GetImageFromArray(img[1].numpy()), labels_dictionary)\n",
    "    evaluations.append((str(index), metrics))\n",
    "    \n",
    "    mia_utils.writeImageArray(predicted_labels, \n",
    "                              os.path.join(inference_directory, f\"ADC_Z_ADC_{index}.nii.gz\"),\n",
    "                               bondid2023_testing.subjects[index].get_label())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mia_utils.interactive_display(predicted_labels, (0,1), \"Bondid 2023 ADC + Z_ADC Inference\", cmap=custom_cmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mia_utils.interactive_display(sitk.GetArrayFromImage(bondid2023_testing.subjects[index].get_label()), (0,1), title=\"Bondid 2023 ADC + Z_ADC Ground truth\", cmap=custom_cmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mia_eval.createDataFrame(evaluations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.experimental.get_memory_info('GPU:0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TACR 6 HIE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tacrhie_training = mia_data.TACRHIE6Dataset(r'/ssd2/jupyter/MIA/split_datasets/tacrhie/training', \"nii.gz\")\n",
    "tacrhie_validation = mia_data.TACRHIE6Dataset(r'/ssd2/jupyter/MIA/split_datasets/tacrhie/validation',  \"nii.gz\")\n",
    "tacrhie_testing = mia_data.TACRHIE6Dataset(r'/ssd2/jupyter/MIA/split_datasets/tacrhie/testing',  \"nii.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_shape = (128, 128, 128)\n",
    "\n",
    "training_cropped = mia_data.CroppedDataset(tacrhie_training.aseg_dataset(), target_shape).dataset()\n",
    "validation_cropped = mia_data.CroppedDataset(tacrhie_validation.aseg_dataset(), target_shape).dataset()\n",
    "testing = mia_data.CroppedDataset(tacrhie_testing.aseg_dataset(), target_shape).dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sliced_example = training_cropped.take(1).flat_map(mia_data.create_slicer(0))\n",
    "plot_slices([x for x in sliced_example], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "dataset_specific_directory = os.path.join(model_directory, \"tacrhie\", \"aseg\")\n",
    "os.makedirs(dataset_specific_directory, exist_ok=True)\n",
    "\n",
    "inference_directory = os.path.join(dataset_specific_directory, \"inference\")\n",
    "os.makedirs(inference_directory, exist_ok=True)\n",
    "\n",
    "with open(r'/ssd2/jupyter/MIA/split_datasets/tacrhie/aseg_labels.json') as file:\n",
    "    labels_dictionary = json.load(file)\n",
    "    del labels_dictionary['0']\n",
    "\n",
    "    labels_dictionary = {v : float(k) for k,v in labels_dictionary.items()}\n",
    "\n",
    "with open(r'/ssd2/jupyter/MIA/split_datasets/tacrhie/aseg_colors.json') as file:\n",
    "    colours_dictionary = json.load(file)\n",
    "    del colours_dictionary['0']\n",
    "        \n",
    "    custom_cmap = ListedColormap([np.array(colours_dictionary[str(k)][:3]) / 255.0 for k in sorted(int(a) for a in colours_dictionary.keys())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = tacrhie_training.subjects[0].get_norm()\n",
    "aseg = tacrhie_training.subjects[0].get_aseg()\n",
    "aseg_aparc = tacrhie_training.subjects[0].get_aseg_aparc()\n",
    "\n",
    "plot_side_by_side([sitk.GetArrayViewFromImage(norm), sitk.GetArrayViewFromImage(aseg), sitk.GetArrayViewFromImage(aseg_aparc)], [\"norm\", \"aseg\", \"aseg+aparc\"] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### aseg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = os.path.join(dataset_specific_directory, \"tacrhie6_aseg.keras\")\n",
    "\n",
    "num_channels = 1\n",
    "batch_size = 128\n",
    "\n",
    "training = training_cropped.flat_map(slicer).batch(batch_size)\n",
    "validation = validation_cropped.flat_map(slicer).batch(batch_size)\n",
    "\n",
    "slices = next(training_cropped.take(1).as_numpy_iterator())\n",
    "\n",
    "input_shape = (*slices[0].shape[1:], num_channels)\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplab_creator = lambda : deeplabv3_compiled(input_size=input_shape, n_classes=len(labels_dictionary) + 1, learning_rate=0.001, enc_filters=64, aspp_filters=512)\n",
    "\n",
    "callbacks_list = [\n",
    "    keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=50),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau( monitor='val_loss', factor=0.5, patience=10, min_lr=1e-6)\n",
    "]\n",
    "\n",
    "fit_params = {\n",
    "    \"callbacks\" : callbacks_list,\n",
    "    \"training_data\" : training,\n",
    "    \"validation_data\" : validation,\n",
    "    'epochs' : 1000\n",
    "}\n",
    "\n",
    "seed_all()\n",
    "best_model_path, history = run_training(deeplab_creator, fit_params, 5, dataset_specific_directory, \"tacrhie_aseg\")\n",
    "\n",
    "if os.path.exists(model_file):\n",
    "    os.remove(model_file)\n",
    "    \n",
    "shutil.copy(best_model_path, model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplab = keras.saving.load_model(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluations = []\n",
    "\n",
    "for index, img in enumerate(testing):\n",
    "    prediction = deeplab.predict(img[0])\n",
    "    predicted_labels = tf.math.argmax(prediction, -1).numpy()\n",
    "\n",
    "    metrics = mia_eval.evaluateImage(sitk.GetImageFromArray(predicted_labels), sitk.GetImageFromArray(img[1].numpy()), labels_dictionary)\n",
    "    evaluations.append((str(index), metrics))\n",
    "    \n",
    "    shape = (256, 256, 256)\n",
    "    begin = (np.array(shape) - predicted_labels.shape) // 2\n",
    "    begin[0] = 0\n",
    "    result = mia_utils.embed_tensor(predicted_labels, shape, begin)\n",
    "\n",
    "    mia_utils.writeImageArray(result, \n",
    "                              os.path.join(inference_directory, f\"{tacrhie_testing.subjects[index].number}.nii.gz\"),\n",
    "                              tacrhie_testing.subjects[index].get_aseg())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.experimental.get_memory_info('GPU:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mia_utils.interactive_display(predicted_labels, (1,256), title=\"TACR-HIE aseg Inference\", cmap=custom_cmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth_array = next(testing.take(1).as_numpy_iterator())[1]\n",
    "\n",
    "mia_utils.interactive_display(truth_array, (1,256), title=\"TACR-HIE aseg Ground truth\", cmap=custom_cmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mia_eval.createDataFrame(evaluations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.experimental.get_memory_info('GPU:0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### aseg + aparc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_shape = (128, 128, 128)\n",
    "\n",
    "training_cropped = mia_data.CroppedDataset(tacrhie_training.aseg_aparc_dataset(), target_shape).dataset()\n",
    "validation_cropped = mia_data.CroppedDataset(tacrhie_validation.aseg_aparc_dataset(), target_shape).dataset()\n",
    "testing = mia_data.CroppedDataset(tacrhie_testing.aseg_aparc_dataset(), target_shape).dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "dataset_specific_directory = os.path.join(model_directory, \"tacrhie\", \"aseg_aparc\")\n",
    "os.makedirs(dataset_specific_directory, exist_ok=True)\n",
    "\n",
    "inference_directory = os.path.join(dataset_specific_directory, \"inference\")\n",
    "os.makedirs(inference_directory, exist_ok=True)\n",
    "\n",
    "with open(r'/ssd2/jupyter/MIA/split_datasets/tacrhie/aseg_aparc_labels.json') as file:\n",
    "    labels_dictionary = json.load(file)\n",
    "    del labels_dictionary['0']\n",
    "\n",
    "    labels_dictionary = {v : float(k) for k,v in labels_dictionary.items()}\n",
    "\n",
    "with open(r'/ssd2/jupyter/MIA/split_datasets/tacrhie/aseg_aparc_colors.json') as file:\n",
    "    colours_dictionary = json.load(file)\n",
    "    del colours_dictionary['0']\n",
    "        \n",
    "    custom_cmap = ListedColormap([np.array(colours_dictionary[str(k)][:3]) / 255.0 for k in sorted(int(a) for a in colours_dictionary.keys())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = tacrhie_training.subjects[0].get_norm()\n",
    "aseg = tacrhie_training.subjects[0].get_aseg()\n",
    "aseg_aparc = tacrhie_training.subjects[0].get_aseg_aparc()\n",
    "\n",
    "plot_side_by_side([sitk.GetArrayViewFromImage(norm), sitk.GetArrayViewFromImage(aseg), sitk.GetArrayViewFromImage(aseg_aparc)], [\"norm\", \"aseg\", \"aseg+aparc\"] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### aseg + aparc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = os.path.join(dataset_specific_directory, \"tacrhie6_aseg_aparc.keras\")\n",
    "\n",
    "num_channels = 1\n",
    "batch_size = 128\n",
    "\n",
    "training_cropped = training_cropped.flat_map(slicer).batch(batch_size)\n",
    "validation_cropped = validation_cropped.flat_map(slicer).batch(batch_size)\n",
    "\n",
    "slices = next(training_cropped.take(1).as_numpy_iterator())\n",
    "\n",
    "input_shape = (*slices[0].shape[1:], num_channels)\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplab_creator = lambda : deeplabv3_compiled(input_size=input_shape, n_classes=len(labels_dictionary) + 1, learning_rate=0.001, enc_filters=64, aspp_filters=512)\n",
    "\n",
    "callbacks_list = [\n",
    "    keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=50),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau( monitor='val_loss', factor=0.5, patience=10, min_lr=1e-6)\n",
    "]\n",
    "\n",
    "fit_params = {\n",
    "    \"callbacks\" : callbacks_list,\n",
    "    \"training_data\" : training_cropped,\n",
    "    \"validation_data\" : validation_cropped,\n",
    "    'epochs' : 1000\n",
    "}\n",
    "\n",
    "seed_all()\n",
    "best_model_path, history = run_training(deeplab_creator, fit_params, 5, dataset_specific_directory, \"tacrhie_aseg_aparc\")\n",
    "\n",
    "if os.path.exists(model_file):\n",
    "    os.remove(model_file)\n",
    "    \n",
    "shutil.copy(best_model_path, model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplab = keras.saving.load_model(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluations = []\n",
    "\n",
    "for index, img in enumerate(testing):\n",
    "    prediction = deeplab.predict(img[0])\n",
    "    predicted_labels = tf.math.argmax(prediction, -1).numpy()\n",
    "\n",
    "    metrics = mia_eval.evaluateImage(sitk.GetImageFromArray(predicted_labels), sitk.GetImageFromArray(img[1].numpy()), labels_dictionary)\n",
    "    evaluations.append((str(index), metrics))\n",
    "    \n",
    "    shape = (256, 256, 256)\n",
    "    begin = (np.array(shape) - predicted_labels.shape) // 2\n",
    "    begin[0] = 0\n",
    "    result = mia_utils.embed_tensor(predicted_labels, shape, begin)\n",
    "\n",
    "    mia_utils.writeImageArray(result, \n",
    "                              os.path.join(inference_directory, f\"{tacrhie_testing.subjects[index].number}.nii.gz\"),\n",
    "                              tacrhie_testing.subjects[index].get_aseg())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.experimental.get_memory_info('GPU:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mia_utils.interactive_display(predicted_labels, (1, 256), title=\"TACR-HIE aseg+aparc Inference\", cmap=custom_cmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth_array = next(testing.take(1).as_numpy_iterator())[1]\n",
    "\n",
    "mia_utils.interactive_display(truth_array, (1, 256), title=\"TACR-HIE aseg+aparc  Ground truth\", cmap=custom_cmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mia_eval.createDataFrame(evaluations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.experimental.get_memory_info('GPU:0')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
